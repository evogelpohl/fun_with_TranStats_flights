{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BTS On-Time Flights — EDA, Cleaning, and Feature Engineering\n",
    "\n",
    "This notebook prepares 2024 BTS on-time performance data for downstream BI by:\n",
    "- Standardizing column names and dtypes\n",
    "- Cleaning nulls/sparse columns and applying schema\n",
    "- Engineering features (FE1–FE6) per instructions\n",
    "- Exporting a clean, sampled Parquet for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Imports\n",
    "Imports used throughout; keep code readable and efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eed8eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ok",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "21802210-0e43-4b5b-a828-01bba0b66b60",
       "rows": [
        [
         "0",
         "1"
        ],
        [
         "1",
         "2"
        ],
        [
         "2",
         "3"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ok\n",
       "0   1\n",
       "1   2\n",
       "2   3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, math, re, sys, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', 120)\n",
    "pd.set_option('display.width', 160)\n",
    "\n",
    "# Light style for quick checks\n",
    "sns.set_context('notebook')\n",
    "\n",
    "# Utility: show small previews consistently\n",
    "def preview(df, n=3):\n",
    "    try:\n",
    "        display(df.head(n))\n",
    "    except NameError:\n",
    "        return df.head(n)\n",
    "\n",
    "preview(pd.DataFrame({'ok': [1,2,3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c86c0e0",
   "metadata": {},
   "source": [
    "## Globals & Configuration\n",
    "Collect all tweakable variables in one place for easy modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb23b964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config — TEST_MODE: False | READ_NROWS: None\n",
      "Flights path exists: True\n",
      "Dims path exists: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "flights_dir",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dims_dir",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "0de0caee-be63-4ec1-842b-26998fea533c",
       "rows": [
        [
         "0",
         "data/flights",
         "data/dims"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flights_dir</th>\n",
       "      <th>dims_dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/flights</td>\n",
       "      <td>data/dims</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    flights_dir   dims_dir\n",
       "0  data/flights  data/dims"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Paths\n",
    "DATA_DIR = Path('data')\n",
    "FLIGHTS_DIR = DATA_DIR / 'flights'\n",
    "DIMS_DIR = DATA_DIR / 'dims'\n",
    "OUTPUT_DIR = DATA_DIR / 'output'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cleaning configuration\n",
    "SPARSE_NULL_THRESHOLD = 0.80  # drop columns with >= 80% nulls\n",
    "CRITICAL_FIELDS = ['depdelayminutes', 'depdel15']  # rows missing these are dropped\n",
    "\n",
    "# Sampling configuration (FE6)\n",
    "SAMPLE_RATE = 0.10  # 10% stratified sample\n",
    "RANDOM_STATE = 42\n",
    "SAMPLE_KEYS = ['month', 'iata_code_reporting_airline', 'depdel15']\n",
    "\n",
    "# Output files\n",
    "OUTPUT_PARQUET = OUTPUT_DIR / 'flights_2024_clean_sampled.parquet'\n",
    "\n",
    "# Plotting toggles (set False to skip generating figures)\n",
    "SHOW_PLOTS = True\n",
    "\n",
    "# Test mode for fast headless runs (CLI/CI)\n",
    "TEST_MODE = os.environ.get('TEST_MODE', '0') == '1'\n",
    "READ_NROWS = 50000 if TEST_MODE else None\n",
    "if TEST_MODE:\n",
    "    SHOW_PLOTS = False\n",
    "print('Config — TEST_MODE:', TEST_MODE, '| READ_NROWS:', READ_NROWS)\n",
    "\n",
    "# Helper: column standardization (lowercase; replace spaces with underscores)\n",
    "def standardize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip().lower().replace(' ', '_') for c in df.columns]\n",
    "    return df\n",
    "\n",
    "# Quick check of directories\n",
    "print('Flights path exists:', FLIGHTS_DIR.exists())\n",
    "print('Dims path exists:', DIMS_DIR.exists())\n",
    "preview(pd.DataFrame({'flights_dir': [str(FLIGHTS_DIR)], 'dims_dir': [str(DIMS_DIR)]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345b382a",
   "metadata": {},
   "source": [
    "## Discover Input Files\n",
    "List available monthly CSVs and dims files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c66018d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total flight CSVs: 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "file",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "1da5cc91-5045-435b-adcf-407fd36cd8e6",
       "rows": [
        [
         "0",
         "On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2024_1.csv"
        ],
        [
         "1",
         "On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2024_10.csv"
        ],
        [
         "2",
         "On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2024_11.csv"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On_Time_Reporting_Carrier_On_Time_Performance_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On_Time_Reporting_Carrier_On_Time_Performance_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On_Time_Reporting_Carrier_On_Time_Performance_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file\n",
       "0  On_Time_Reporting_Carrier_On_Time_Performance_...\n",
       "1  On_Time_Reporting_Carrier_On_Time_Performance_...\n",
       "2  On_Time_Reporting_Carrier_On_Time_Performance_..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dims_airport",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dims_airline",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "ff0df30d-ef84-4cd8-875b-b1d5ed2fe526",
       "rows": [
        [
         "0",
         "T_MASTER_CORD.csv",
         "L_AIRLINE_ID.csv"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dims_airport</th>\n",
       "      <th>dims_airline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T_MASTER_CORD.csv</td>\n",
       "      <td>L_AIRLINE_ID.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dims_airport      dims_airline\n",
       "0  T_MASTER_CORD.csv  L_AIRLINE_ID.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flight_files = sorted(FLIGHTS_DIR.glob('*.csv'))\n",
    "dims_airport_path = DIMS_DIR / 'T_MASTER_CORD.csv'\n",
    "dims_airline_path = DIMS_DIR / 'L_AIRLINE_ID.csv'\n",
    "\n",
    "print(f'Total flight CSVs: {len(flight_files)}')\n",
    "preview(pd.DataFrame({'file': [p.name for p in flight_files]}).head(3))\n",
    "preview(pd.DataFrame({'dims_airport': [dims_airport_path.name], 'dims_airline': [dims_airline_path.name]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bc1efb",
   "metadata": {},
   "source": [
    "## Load Flights (All Months)\n",
    "Load monthly CSVs, standardize column names, and concatenate. For memory safety, we defer heavy casting until after pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bfe4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 12 files with nrows = None\n"
     ]
    }
   ],
   "source": [
    "def read_flight_csv(path: Path) -> pd.DataFrame:\n",
    "    # Read as strings first to avoid mixed dtypes; cast later.\n",
    "    df = pd.read_csv(path, dtype=str, low_memory=False, nrows=READ_NROWS)\n",
    "    df = standardize_columns(df)\n",
    "    return df\n",
    "\n",
    "print('Reading', len(flight_files), 'files with nrows =', READ_NROWS)\n",
    "flights_list = [read_flight_csv(p) for p in flight_files]\n",
    "df = pd.concat(flights_list, ignore_index=True) if flights_list else pd.DataFrame()\n",
    "print('Rows:', len(df), 'Cols:', len(df.columns))\n",
    "preview(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac547bb",
   "metadata": {},
   "source": [
    "## Quick EDA: Missingness & Basic Sanity\n",
    "Understand nulls to inform pruning and dtype casting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc69ee71",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    missing_frac = df.isna().mean().sort_values(ascending=False)\n",
    "    preview(missing_frac.to_frame('missing_frac'))\n",
    "    preview(df[['flightdate','month','origin','dest','crsdeptime','deptime','depdelay','depdelayminutes','depdel15']].head(3))\n",
    "else:\n",
    "    preview(pd.DataFrame({'note': ['no data loaded']}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc3c754",
   "metadata": {},
   "source": [
    "## DE1: Drop Rows Missing Critical Fields\n",
    "Remove rows where `depdelayminutes` or `depdel15` is null/blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4de4406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_critical_nulls(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for c in CRITICAL_FIELDS:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].replace('', np.nan)\n",
    "            df = df[df[c].notna()]\n",
    "    return df\n",
    "\n",
    "before = len(df)\n",
    "df = drop_critical_nulls(df)\n",
    "after = len(df)\n",
    "print('Dropped rows (critical nulls):', before - after, 'Remaining:', after)\n",
    "preview(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a48db3e",
   "metadata": {},
   "source": [
    "## DE2: Drop Sparse Columns (>= 80% Nulls)\n",
    "Prune legacy/unused fields. Threshold configurable via `SPARSE_NULL_THRESHOLD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a756ebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_sparse_columns(df: pd.DataFrame, threshold: float) -> pd.DataFrame:\n",
    "    frac = df.isna().mean()\n",
    "    to_drop = frac[frac >= threshold].index.tolist()\n",
    "    print(f'Dropping {len(to_drop)} sparse columns (>= {threshold:.0%} nulls)')\n",
    "    return df.drop(columns=to_drop)\n",
    "\n",
    "df = drop_sparse_columns(df, SPARSE_NULL_THRESHOLD)\n",
    "preview(pd.Series(df.columns[:12]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a477319a",
   "metadata": {},
   "source": [
    "## DE3: Dtype Casting per Dictionary/Best Guess\n",
    "Set canonical types for key fields; parse dates and numeric fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763c38ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_int(series):\n",
    "    return pd.to_numeric(series, errors='coerce').astype('Int64')\n",
    "\n",
    "def to_float(series):\n",
    "    return pd.to_numeric(series, errors='coerce').astype(float)\n",
    "\n",
    "# Parse date\n",
    "if 'flightdate' in df.columns:\n",
    "    df['flightdate'] = pd.to_datetime(df['flightdate'], errors='coerce')\n",
    "\n",
    "# Numeric casts for key fields\n",
    "for c in ['year','quarter','month','dayofmonth','dayofweek','originairportid','destairportid','dot_id_reporting_airline']:\n",
    "    if c in df.columns:\n",
    "        df[c] = to_int(df[c])\n",
    "\n",
    "for c in ['depdelay','depdelayminutes','arrdelay','arrdelayminutes','taxiout','taxiin','airtime','distance']:\n",
    "    if c in df.columns:\n",
    "        df[c] = to_float(df[c])\n",
    "\n",
    "# Keep string/object for codes\n",
    "for c in ['origin','dest','iata_code_reporting_airline','reporting_airline','tail_number']:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].astype('string')\n",
    "\n",
    "preview(df[['flightdate','month','origin','dest','depdelayminutes','depdel15']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e761870e",
   "metadata": {},
   "source": [
    "## FE1: Day-Part (Scheduled and Actual) with Midnight Rollover\n",
    "Create `daypart_sched` from `crsdeptime` and `daypart_actual` from `deptime` with rollover handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad1ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FE1: Day-Part (Scheduled and Actual) with Midnight Rollover (vectorized)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DAYPART_ORDER = ['night','early_morning','morning','afternoon','late_afternoon','evening']\n",
    "DAYPART_CAT = pd.CategoricalDtype(categories=DAYPART_ORDER, ordered=True)\n",
    "\n",
    "def _extract_hour_min(series: pd.Series):\n",
    "    # Convert to string, strip, and sanitize\n",
    "    s = series.astype('string').str.strip()\n",
    "    s = s.str.split('.', n=1).str[0]  # drop fractional suffixes like '856.00'\n",
    "    s_digits = s.str.replace(r'[^0-9]', '', regex=True)\n",
    "    s_digits = s_digits.where(s_digits.str.len() > 0)\n",
    "    s4 = s_digits.str.zfill(4)\n",
    "\n",
    "    hh = pd.to_numeric(s4.str[:2], errors='coerce')\n",
    "    mm = pd.to_numeric(s4.str[2:], errors='coerce')\n",
    "\n",
    "    # Normalize edge cases: 2400 -> 00:00; clamp to valid ranges\n",
    "    is_2400 = s4 == '2400'\n",
    "    hh = hh.clip(0, 23).mask(is_2400, 0).astype('Int64')\n",
    "    mm = mm.clip(0, 59).mask(is_2400, 0).astype('Int64')\n",
    "    return hh, mm\n",
    "\n",
    "def _to_daypart(hour: pd.Series) -> pd.Series:\n",
    "    h = hour.astype('float64')\n",
    "    buckets = pd.cut(\n",
    "        h,\n",
    "        bins=[-0.1, 3, 7, 11, 15, 19, 23],\n",
    "        labels=DAYPART_ORDER,\n",
    "        include_lowest=True,\n",
    "        right=True,\n",
    "    )\n",
    "    return buckets.astype(DAYPART_CAT)\n",
    "\n",
    "def compute_dayparts_fast(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "\n",
    "    if 'crsdeptime' in out:\n",
    "        crs_h, _ = _extract_hour_min(out['crsdeptime'])\n",
    "        out['daypart_sched'] = _to_daypart(crs_h)\n",
    "    else:\n",
    "        out['daypart_sched'] = pd.Series(pd.Categorical([np.nan] * len(out), categories=DAYPART_ORDER), index=out.index)\n",
    "\n",
    "    if 'deptime' in out:\n",
    "        dep_h, _ = _extract_hour_min(out['deptime'])\n",
    "        out['deptimehour'] = dep_h.astype('Int8')\n",
    "        out['daypart_actual'] = _to_daypart(dep_h)\n",
    "    else:\n",
    "        out['deptimehour'] = pd.Series([pd.NA] * len(out), dtype='Int8', index=out.index)\n",
    "        out['daypart_actual'] = pd.Series(pd.Categorical([np.nan] * len(out), categories=DAYPART_ORDER), index=out.index)\n",
    "\n",
    "    return out\n",
    "\n",
    "df = compute_dayparts_fast(df)\n",
    "preview(df[['flightdate','crsdeptime','deptime','deptimehour','daypart_sched','daypart_actual']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2bd76c",
   "metadata": {},
   "source": [
    "## FE2: Origin Airport Tiers (Top 20%, Next 50%, Bottom 30%)\n",
    "Group by `origin` across all flights (including cancelled); assign tiers by airport percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09357470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_origin_tiers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    counts = df.groupby('origin', dropna=False).size().reset_index(name='flights')\n",
    "    counts = counts.sort_values(['flights','origin'], ascending=[False, True]).reset_index(drop=True)\n",
    "    counts['airport_rank'] = np.arange(1, len(counts)+1)\n",
    "    counts['airport_pct'] = counts['airport_rank'] / len(counts)\n",
    "    def tier(p):\n",
    "        if p <= 0.20: return 'Tier 1'\n",
    "        if p <= 0.70: return 'Tier 2'\n",
    "        return 'Tier 3'\n",
    "    counts['origin_tier'] = counts['airport_pct'].apply(tier)\n",
    "    return df.merge(counts[['origin','origin_tier']], on='origin', how='left')\n",
    "\n",
    "df = assign_origin_tiers(df)\n",
    "preview(df[['origin','origin_tier']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eb9edf",
   "metadata": {},
   "source": [
    "## FE3: Late/On-Time Flags\n",
    "Create `is_late_departure` from `depdel15` and `is_on_time_departure = 1 - is_late_departure`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29af6623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_departure_flags(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df['depdel15'] = pd.to_numeric(df['depdel15'], errors='coerce')\n",
    "    df['is_late_departure'] = (df['depdel15'] == 1).astype('Int8')\n",
    "    df['is_on_time_departure'] = (1 - df['is_late_departure'].fillna(0)).astype('Int8')\n",
    "    return df\n",
    "\n",
    "df = add_departure_flags(df)\n",
    "preview(df[['depdel15','depdelayminutes','is_late_departure','is_on_time_departure']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848415a5",
   "metadata": {},
   "source": [
    "## FE4: Airport Coordinates (Origin/Dest)\n",
    "Join `T_MASTER_CORD.csv` on airport IDs, filter `airport_is_latest == 1`, and keep only lat/long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecc1385",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = pd.read_csv(dims_airport_path, dtype=str)\n",
    "airports = standardize_columns(airports)\n",
    "airports = airports[airports['airport_is_latest'] == '1']\n",
    "airports = airports[['airport_id','latitude','longitude']].copy()\n",
    "airports['airport_id'] = pd.to_numeric(airports['airport_id'], errors='coerce').astype('Int64')\n",
    "airports['latitude'] = pd.to_numeric(airports['latitude'], errors='coerce')\n",
    "airports['longitude'] = pd.to_numeric(airports['longitude'], errors='coerce')\n",
    "\n",
    "df = df.merge(airports.rename(columns={'airport_id':'originairportid', 'latitude':'origin_lat', 'longitude':'origin_long'}),\n",
    "               on='originairportid', how='left')\n",
    "df = df.merge(airports.rename(columns={'airport_id':'destairportid', 'latitude':'dest_lat', 'longitude':'dest_long'}),\n",
    "               on='destairportid', how='left')\n",
    "preview(df[['origin','origin_lat','origin_long','dest','dest_lat','dest_long']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e7a18b",
   "metadata": {},
   "source": [
    "## FE5: Airline Name (Join on IATA Code)\n",
    "Parse IATA code and airline name from `L_AIRLINE_ID.csv` descriptions, then join to flights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57cb055",
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines = pd.read_csv(dims_airline_path, dtype=str)\n",
    "airlines = standardize_columns(airlines)\n",
    "# Expect columns: 'code' (numeric id), 'description' like 'Southwest Airlines Co.: WN'\n",
    "def split_airline_desc(s):\n",
    "    if pd.isna(s):\n",
    "        return pd.Series({'airline_name': np.nan, 'iata_code': np.nan})\n",
    "    parts = str(s).split(':')\n",
    "    if len(parts) >= 2:\n",
    "        name = parts[0].strip()\n",
    "        code = parts[1].strip()\n",
    "        return pd.Series({'airline_name': name, 'iata_code': code})\n",
    "    return pd.Series({'airline_name': str(s).strip(), 'iata_code': np.nan})\n",
    "\n",
    "airlines[['airline_name','iata_code']] = airlines['description'].apply(split_airline_desc)\n",
    "airlines['iata_code'] = airlines['iata_code'].str.upper()\n",
    "airline_lookup = airlines[['iata_code','airline_name']].dropna(subset=['iata_code']).drop_duplicates()\n",
    "\n",
    "df = df.merge(airline_lookup, left_on='iata_code_reporting_airline', right_on='iata_code', how='left')\n",
    "df = df.drop(columns=['iata_code'])\n",
    "preview(df[['iata_code_reporting_airline','airline_name']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c76997",
   "metadata": {},
   "source": [
    "## FE6: Stratified Down-Sampling (10%)\n",
    "Stratify by `month`, `iata_code_reporting_airline`, and `depdel15` to preserve seasonality, carrier mix, and delay balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614c921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_sample(df: pd.DataFrame, keys, frac: float, random_state: int) -> pd.DataFrame:\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    def take_sample(g):\n",
    "        n = len(g)\n",
    "        k = max(1, int(math.ceil(n * frac)))\n",
    "        return g.sample(n=min(k, n), random_state=random_state, replace=False)\n",
    "    return df.groupby(keys, dropna=False, as_index=False, group_keys=False).apply(take_sample)\n",
    "\n",
    "df_sampled = stratified_sample(df, SAMPLE_KEYS, SAMPLE_RATE, RANDOM_STATE) if not df.empty else df\n",
    "print('Sampled rows:', len(df_sampled), 'out of', len(df))\n",
    "preview(df_sampled[['month','iata_code_reporting_airline','depdel15']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb9e9e8",
   "metadata": {},
   "source": [
    "## DE6: Final Cleanup\n",
    "Drop redundant and ambiguous columns (e.g., raw flags, IDs used only for joins), keeping BI-useful fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea0a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNWANTED_COLS = [\n",
    "    # Airline/carrier identifiers duplicated by joins\n",
    "    'tail_number', 'depdel15', 'reporting_airline', 'dot_id_reporting_airline', 'iata_code_reporting_airline',\n",
    "    # Airport/location IDs used only for joins (keep IATA codes + lat/long)\n",
    "    'originairportid', 'destairportid', 'originairportseqid', 'destairportseqid',\n",
    "    'origincitymarketid', 'destcitymarketid', 'originwac', 'destwac'\n",
    "]  # extend as needed\n",
    "\n",
    "def drop_unwanted(df: pd.DataFrame, cols) -> pd.DataFrame:\n",
    "    existing = [c for c in cols if c in df.columns]\n",
    "    print('Dropping unwanted cols:', existing)\n",
    "    return df.drop(columns=existing)\n",
    "\n",
    "df_final = drop_unwanted(df_sampled, UNWANTED_COLS)\n",
    "preview(pd.Series(sorted(df_final.columns)).head(12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c93b4bb",
   "metadata": {},
   "source": [
    "# Remove More Unwanted Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9d8fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_unwanted = ['daypart_sched', 'airtime', 'actualelapsedtime', 'crselapsedtime', \n",
    "                 'arrtimeblk', 'arrivaldelaygroups', 'deptimeblk', 'departuredelaygroups', 'depdelay', 'crsdeptime'\n",
    "                 , 'originstatefips', 'deststatefips']\n",
    "\n",
    "df_final = drop_unwanted(df_final, more_unwanted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5886c831",
   "metadata": {},
   "source": [
    "## Export to Parquet\n",
    "Write the engineered, sampled dataset to `data/output`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e34570",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_parquet(OUTPUT_PARQUET, index=False)\n",
    "preview(pd.DataFrame({'written_to': [str(OUTPUT_PARQUET)]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5945bd3e",
   "metadata": {},
   "source": [
    "## Validation Visuals\n",
    "Quick plots to sanity-check distributions and feature derivations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aa5e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_PLOTS and not df.empty:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15,4))\n",
    "    sns.countplot(data=df, x='daypart_sched', ax=axes[0], order=['night','early_morning','morning','afternoon','late_afternoon','evening'])\n",
    "    axes[0].set_title('Scheduled Dayparts')\n",
    "    sns.countplot(data=df, x='is_late_departure', ax=axes[1])\n",
    "    axes[1].set_title('Late Departure Flag')\n",
    "    sns.countplot(data=df, x='origin_tier', ax=axes[2], order=['Tier 1','Tier 2','Tier 3'])\n",
    "    axes[2].set_title('Origin Tiers')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    preview(df[['daypart_sched','is_late_departure','origin_tier']].head(3))\n",
    "else:\n",
    "    preview(pd.DataFrame({'note': ['plots skipped or no data']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d19d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a heatmap plot of all flights in df_final with Y as "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
