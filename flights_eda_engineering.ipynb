{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BTS On-Time Flights — EDA, Cleaning, and Feature Engineering\n",
    "\n",
    "This notebook prepares 2024 BTS on-time performance data for downstream BI by:\n",
    "- Standardizing column names and dtypes\n",
    "- Cleaning nulls/sparse columns and applying schema\n",
    "- Engineering features (FE1–FE6) per instructions\n",
    "- Exporting a clean, sampled Parquet for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Imports\n",
    "Imports used throughout; keep code readable and efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eed8eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, re, sys, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', 120)\n",
    "pd.set_option('display.width', 160)\n",
    "\n",
    "# Light style for quick checks\n",
    "sns.set_context('notebook')\n",
    "\n",
    "# Utility: show small previews consistently\n",
    "def preview(df, n=3):\n",
    "    try:\n",
    "        display(df.head(n))\n",
    "    except NameError:\n",
    "        return df.head(n)\n",
    "\n",
    "preview(pd.DataFrame({'ok': [1,2,3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c86c0e0",
   "metadata": {},
   "source": [
    "## Globals & Configuration\n",
    "Collect all tweakable variables in one place for easy modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb23b964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_DIR = Path('data')\n",
    "FLIGHTS_DIR = DATA_DIR / 'flights'\n",
    "DIMS_DIR = DATA_DIR / 'dims'\n",
    "OUTPUT_DIR = DATA_DIR / 'output'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cleaning configuration\n",
    "SPARSE_NULL_THRESHOLD = 0.80  # drop columns with >= 80% nulls\n",
    "CRITICAL_FIELDS = ['depdelayminutes', 'depdel15']  # rows missing these are dropped\n",
    "\n",
    "# Sampling configuration (FE6)\n",
    "SAMPLE_RATE = 0.10  # 10% stratified sample\n",
    "RANDOM_STATE = 42\n",
    "SAMPLE_KEYS = ['month', 'iata_code_reporting_airline', 'depdel15']\n",
    "\n",
    "# Output files\n",
    "OUTPUT_PARQUET = OUTPUT_DIR / 'flights_2024_clean_sampled.parquet'\n",
    "\n",
    "# Plotting toggles (set False to skip generating figures)\n",
    "SHOW_PLOTS = True\n",
    "\n",
    "# Test mode for fast headless runs (CLI/CI)\n",
    "TEST_MODE = os.environ.get('TEST_MODE', '0') == '1'\n",
    "READ_NROWS = 50000 if TEST_MODE else None\n",
    "if TEST_MODE:\n",
    "    SHOW_PLOTS = False\n",
    "print('Config — TEST_MODE:', TEST_MODE, '| READ_NROWS:', READ_NROWS)\n",
    "\n",
    "# Helper: column standardization (lowercase; replace spaces with underscores)\n",
    "def standardize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip().lower().replace(' ', '_') for c in df.columns]\n",
    "    return df\n",
    "\n",
    "# Quick check of directories\n",
    "print('Flights path exists:', FLIGHTS_DIR.exists())\n",
    "print('Dims path exists:', DIMS_DIR.exists())\n",
    "preview(pd.DataFrame({'flights_dir': [str(FLIGHTS_DIR)], 'dims_dir': [str(DIMS_DIR)]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345b382a",
   "metadata": {},
   "source": [
    "## Discover Input Files\n",
    "List available monthly CSVs and dims files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c66018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_files = sorted(FLIGHTS_DIR.glob('*.csv'))\n",
    "dims_airport_path = DIMS_DIR / 'T_MASTER_CORD.csv'\n",
    "dims_airline_path = DIMS_DIR / 'L_AIRLINE_ID.csv'\n",
    "\n",
    "print(f'Total flight CSVs: {len(flight_files)}')\n",
    "preview(pd.DataFrame({'file': [p.name for p in flight_files]}).head(3))\n",
    "preview(pd.DataFrame({'dims_airport': [dims_airport_path.name], 'dims_airline': [dims_airline_path.name]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bc1efb",
   "metadata": {},
   "source": [
    "## Load Flights (All Months)\n",
    "Load monthly CSVs, standardize column names, and concatenate. For memory safety, we defer heavy casting until after pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bfe4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_flight_csv(path: Path) -> pd.DataFrame:\n",
    "    # Read as strings first to avoid mixed dtypes; cast later.\n",
    "    df = pd.read_csv(path, dtype=str, low_memory=False, nrows=READ_NROWS)\n",
    "    df = standardize_columns(df)\n",
    "    return df\n",
    "\n",
    "print('Reading', len(flight_files), 'files with nrows =', READ_NROWS)\n",
    "flights_list = [read_flight_csv(p) for p in flight_files]\n",
    "df = pd.concat(flights_list, ignore_index=True) if flights_list else pd.DataFrame()\n",
    "print('Rows:', len(df), 'Cols:', len(df.columns))\n",
    "preview(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac547bb",
   "metadata": {},
   "source": [
    "## Quick EDA: Missingness & Basic Sanity\n",
    "Understand nulls to inform pruning and dtype casting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc69ee71",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    missing_frac = df.isna().mean().sort_values(ascending=False)\n",
    "    preview(missing_frac.to_frame('missing_frac'))\n",
    "    preview(df[['flightdate','month','origin','dest','crsdeptime','deptime','depdelay','depdelayminutes','depdel15']].head(3))\n",
    "else:\n",
    "    preview(pd.DataFrame({'note': ['no data loaded']}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc3c754",
   "metadata": {},
   "source": [
    "## DE1: Drop Rows Missing Critical Fields\n",
    "Remove rows where `depdelayminutes` or `depdel15` is null/blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4de4406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_critical_nulls(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for c in CRITICAL_FIELDS:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].replace('', np.nan)\n",
    "            df = df[df[c].notna()]\n",
    "    return df\n",
    "\n",
    "before = len(df)\n",
    "df = drop_critical_nulls(df)\n",
    "after = len(df)\n",
    "print('Dropped rows (critical nulls):', before - after, 'Remaining:', after)\n",
    "preview(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a48db3e",
   "metadata": {},
   "source": [
    "## DE2: Drop Sparse Columns (>= 80% Nulls)\n",
    "Prune legacy/unused fields. Threshold configurable via `SPARSE_NULL_THRESHOLD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a756ebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_sparse_columns(df: pd.DataFrame, threshold: float) -> pd.DataFrame:\n",
    "    frac = df.isna().mean()\n",
    "    to_drop = frac[frac >= threshold].index.tolist()\n",
    "    print(f'Dropping {len(to_drop)} sparse columns (>= {threshold:.0%} nulls)')\n",
    "    return df.drop(columns=to_drop)\n",
    "\n",
    "df = drop_sparse_columns(df, SPARSE_NULL_THRESHOLD)\n",
    "preview(pd.Series(df.columns[:12]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a477319a",
   "metadata": {},
   "source": [
    "## DE3: Dtype Casting per Dictionary/Best Guess\n",
    "Set canonical types for key fields; parse dates and numeric fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763c38ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_int(series):\n",
    "    return pd.to_numeric(series, errors='coerce').astype('Int64')\n",
    "\n",
    "def to_float(series):\n",
    "    return pd.to_numeric(series, errors='coerce').astype(float)\n",
    "\n",
    "# Parse date\n",
    "if 'flightdate' in df.columns:\n",
    "    df['flightdate'] = pd.to_datetime(df['flightdate'], errors='coerce')\n",
    "\n",
    "# Numeric casts for key fields\n",
    "for c in ['year','quarter','month','dayofmonth','dayofweek','originairportid','destairportid','dot_id_reporting_airline']:\n",
    "    if c in df.columns:\n",
    "        df[c] = to_int(df[c])\n",
    "\n",
    "for c in ['depdelay','depdelayminutes','arrdelay','arrdelayminutes','taxiout','taxiin','airtime','distance']:\n",
    "    if c in df.columns:\n",
    "        df[c] = to_float(df[c])\n",
    "\n",
    "# Keep string/object for codes\n",
    "for c in ['origin','dest','iata_code_reporting_airline','reporting_airline','tail_number']:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].astype('string')\n",
    "\n",
    "preview(df[['flightdate','month','origin','dest','depdelayminutes','depdel15']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e761870e",
   "metadata": {},
   "source": [
    "## FE1: Day-Part (Scheduled and Actual) with Midnight Rollover\n",
    "Create `daypart_sched` from `crsdeptime` and `daypart_actual` from `deptime` with rollover handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad1ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date, time, timedelta\n",
    "\n",
    "def parse_hhmm(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    s = str(x).strip()\n",
    "    if s == '':\n",
    "        return np.nan\n",
    "    # Handle decimal-like values (e.g., '856.00')\n",
    "    s = s.split('.')[0]\n",
    "    s = s.zfill(4) if s.isdigit() else re.sub(r'[^0-9]', '', s).zfill(4)\n",
    "    hh = int(s[:2])\n",
    "    mm = int(s[2:])\n",
    "    if hh == 24 and mm == 0:\n",
    "        hh, mm = 0, 0\n",
    "    hh = max(0, min(23, hh))\n",
    "    mm = max(0, min(59, mm))\n",
    "    return time(hh, mm)\n",
    "\n",
    "def daypart_from_time(t: time):\n",
    "    if pd.isna(t):\n",
    "        return np.nan\n",
    "    h = t.hour\n",
    "    if 0 <= h <= 3: return 'night'\n",
    "    if 4 <= h <= 7: return 'early_morning'\n",
    "    if 8 <= h <= 11: return 'morning'\n",
    "    if 12 <= h <= 15: return 'afternoon'\n",
    "    if 16 <= h <= 19: return 'late_afternoon'\n",
    "    return 'evening'\n",
    "\n",
    "def compute_dayparts(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Reset index to ensure positional access works reliably after drops\n",
    "    df = df.copy().reset_index(drop=True)\n",
    "    crs_t = df['crsdeptime'].apply(parse_hhmm) if 'crsdeptime' in df else pd.Series([np.nan] * len(df))\n",
    "    dep_t = df['deptime'].apply(parse_hhmm) if 'deptime' in df else pd.Series([np.nan] * len(df))\n",
    "\n",
    "    # Scheduled daypart\n",
    "    df['daypart_sched'] = [daypart_from_time(t) for t in crs_t]\n",
    "\n",
    "    # Actual daypart with midnight rollover if depdelay >= 0 and deptime < crsdeptime\n",
    "    if 'flightdate' in df.columns:\n",
    "        sched_dt = [pd.NaT] * len(df)\n",
    "        act_dt = [pd.NaT] * len(df)\n",
    "        for i in range(len(df)):\n",
    "            # Use positional access to avoid KeyError with non-consecutive indexes\n",
    "            fd = df.iloc[i]['flightdate']\n",
    "            ct = crs_t.iloc[i] if isinstance(crs_t, pd.Series) else crs_t\n",
    "            at = dep_t.iloc[i] if isinstance(dep_t, pd.Series) else dep_t\n",
    "            if not pd.isna(fd) and isinstance(ct, time):\n",
    "                sched_dt[i] = datetime.combine(fd.date() if isinstance(fd, pd.Timestamp) else fd, ct)\n",
    "            if not pd.isna(fd) and isinstance(at, time):\n",
    "                base = datetime.combine(fd.date() if isinstance(fd, pd.Timestamp) else fd, at)\n",
    "                # Rollover rule\n",
    "                dep_delay = df.iloc[i]['depdelay'] if 'depdelay' in df.columns else np.nan\n",
    "                if not pd.isna(dep_delay) and dep_delay >= 0 and isinstance(ct, time) and at < ct:\n",
    "                    base = base + timedelta(days=1)\n",
    "                act_dt[i] = base\n",
    "        df['daypart_actual'] = [daypart_from_time(d.time()) if not pd.isna(d) else np.nan for d in act_dt]\n",
    "    else:\n",
    "        df['daypart_actual'] = np.nan\n",
    "    return df\n",
    "\n",
    "df = compute_dayparts(df)\n",
    "preview(df[['flightdate','crsdeptime','deptime','depdelay','daypart_sched','daypart_actual']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2bd76c",
   "metadata": {},
   "source": [
    "## FE2: Origin Airport Tiers (Top 20%, Next 50%, Bottom 30%)\n",
    "Group by `origin` across all flights (including cancelled); assign tiers by airport percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09357470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_origin_tiers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    counts = df.groupby('origin', dropna=False).size().reset_index(name='flights')\n",
    "    counts = counts.sort_values(['flights','origin'], ascending=[False, True]).reset_index(drop=True)\n",
    "    counts['airport_rank'] = np.arange(1, len(counts)+1)\n",
    "    counts['airport_pct'] = counts['airport_rank'] / len(counts)\n",
    "    def tier(p):\n",
    "        if p <= 0.20: return 'Tier 1'\n",
    "        if p <= 0.70: return 'Tier 2'\n",
    "        return 'Tier 3'\n",
    "    counts['origin_tier'] = counts['airport_pct'].apply(tier)\n",
    "    return df.merge(counts[['origin','origin_tier']], on='origin', how='left')\n",
    "\n",
    "df = assign_origin_tiers(df)\n",
    "preview(df[['origin','origin_tier']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eb9edf",
   "metadata": {},
   "source": [
    "## FE3: Late/On-Time Flags\n",
    "Create `is_late_departure` from `depdel15` and `is_on_time_departure = 1 - is_late_departure`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29af6623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_departure_flags(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df['depdel15'] = pd.to_numeric(df['depdel15'], errors='coerce')\n",
    "    df['is_late_departure'] = (df['depdel15'] == 1).astype('Int8')\n",
    "    df['is_on_time_departure'] = (1 - df['is_late_departure'].fillna(0)).astype('Int8')\n",
    "    return df\n",
    "\n",
    "df = add_departure_flags(df)\n",
    "preview(df[['depdel15','depdelayminutes','is_late_departure','is_on_time_departure']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848415a5",
   "metadata": {},
   "source": [
    "## FE4: Airport Coordinates (Origin/Dest)\n",
    "Join `T_MASTER_CORD.csv` on airport IDs, filter `airport_is_latest == 1`, and keep only lat/long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecc1385",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = pd.read_csv(dims_airport_path, dtype=str)\n",
    "airports = standardize_columns(airports)\n",
    "airports = airports[airports['airport_is_latest'] == '1']\n",
    "airports = airports[['airport_id','latitude','longitude']].copy()\n",
    "airports['airport_id'] = pd.to_numeric(airports['airport_id'], errors='coerce').astype('Int64')\n",
    "airports['latitude'] = pd.to_numeric(airports['latitude'], errors='coerce')\n",
    "airports['longitude'] = pd.to_numeric(airports['longitude'], errors='coerce')\n",
    "\n",
    "df = df.merge(airports.rename(columns={'airport_id':'originairportid', 'latitude':'origin_lat', 'longitude':'origin_long'}),\n",
    "               on='originairportid', how='left')\n",
    "df = df.merge(airports.rename(columns={'airport_id':'destairportid', 'latitude':'dest_lat', 'longitude':'dest_long'}),\n",
    "               on='destairportid', how='left')\n",
    "preview(df[['origin','origin_lat','origin_long','dest','dest_lat','dest_long']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e7a18b",
   "metadata": {},
   "source": [
    "## FE5: Airline Name (Join on IATA Code)\n",
    "Parse IATA code and airline name from `L_AIRLINE_ID.csv` descriptions, then join to flights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57cb055",
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines = pd.read_csv(dims_airline_path, dtype=str)\n",
    "airlines = standardize_columns(airlines)\n",
    "# Expect columns: 'code' (numeric id), 'description' like 'Southwest Airlines Co.: WN'\n",
    "def split_airline_desc(s):\n",
    "    if pd.isna(s):\n",
    "        return pd.Series({'airline_name': np.nan, 'iata_code': np.nan})\n",
    "    parts = str(s).split(':')\n",
    "    if len(parts) >= 2:\n",
    "        name = parts[0].strip()\n",
    "        code = parts[1].strip()\n",
    "        return pd.Series({'airline_name': name, 'iata_code': code})\n",
    "    return pd.Series({'airline_name': str(s).strip(), 'iata_code': np.nan})\n",
    "\n",
    "airlines[['airline_name','iata_code']] = airlines['description'].apply(split_airline_desc)\n",
    "airlines['iata_code'] = airlines['iata_code'].str.upper()\n",
    "airline_lookup = airlines[['iata_code','airline_name']].dropna(subset=['iata_code']).drop_duplicates()\n",
    "\n",
    "df = df.merge(airline_lookup, left_on='iata_code_reporting_airline', right_on='iata_code', how='left')\n",
    "df = df.drop(columns=['iata_code'])\n",
    "preview(df[['iata_code_reporting_airline','airline_name']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c76997",
   "metadata": {},
   "source": [
    "## FE6: Stratified Down-Sampling (10%)\n",
    "Stratify by `month`, `iata_code_reporting_airline`, and `depdel15` to preserve seasonality, carrier mix, and delay balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614c921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_sample(df: pd.DataFrame, keys, frac: float, random_state: int) -> pd.DataFrame:\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    def take_sample(g):\n",
    "        n = len(g)\n",
    "        k = max(1, int(math.ceil(n * frac)))\n",
    "        return g.sample(n=min(k, n), random_state=random_state, replace=False)\n",
    "    return df.groupby(keys, dropna=False, as_index=False, group_keys=False).apply(take_sample)\n",
    "\n",
    "df_sampled = stratified_sample(df, SAMPLE_KEYS, SAMPLE_RATE, RANDOM_STATE) if not df.empty else df\n",
    "print('Sampled rows:', len(df_sampled), 'out of', len(df))\n",
    "preview(df_sampled[['month','iata_code_reporting_airline','depdel15']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb9e9e8",
   "metadata": {},
   "source": [
    "## DE6: Final Cleanup\n",
    "Drop redundant and ambiguous columns (e.g., raw flags, IDs used only for joins), keeping BI-useful fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea0a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNWANTED_COLS = [\n",
    "    'tail_number', 'depdel15', 'reporting_airline', 'dot_id_reporting_airline', 'iata_code_reporting_airline'\n",
    "]  # extend as needed\n",
    "\n",
    "def drop_unwanted(df: pd.DataFrame, cols) -> pd.DataFrame:\n",
    "    existing = [c for c in cols if c in df.columns]\n",
    "    print('Dropping unwanted cols:', existing)\n",
    "    return df.drop(columns=existing)\n",
    "\n",
    "df_final = drop_unwanted(df_sampled, UNWANTED_COLS)\n",
    "preview(pd.Series(sorted(df_final.columns)).head(12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5886c831",
   "metadata": {},
   "source": [
    "## Export to Parquet\n",
    "Write the engineered, sampled dataset to `data/output`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e34570",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_parquet(OUTPUT_PARQUET, index=False)\n",
    "preview(pd.DataFrame({'written_to': [str(OUTPUT_PARQUET)]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5945bd3e",
   "metadata": {},
   "source": [
    "## Validation Visuals\n",
    "Quick plots to sanity-check distributions and feature derivations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aa5e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_PLOTS and not df.empty:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15,4))\n",
    "    sns.countplot(data=df, x='daypart_sched', ax=axes[0], order=['night','early_morning','morning','afternoon','late_afternoon','evening'])\n",
    "    axes[0].set_title('Scheduled Dayparts')\n",
    "    sns.countplot(data=df, x='is_late_departure', ax=axes[1])\n",
    "    axes[1].set_title('Late Departure Flag')\n",
    "    sns.countplot(data=df, x='origin_tier', ax=axes[2], order=['Tier 1','Tier 2','Tier 3'])\n",
    "    axes[2].set_title('Origin Tiers')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    preview(df[['daypart_sched','is_late_departure','origin_tier']].head(3))\n",
    "else:\n",
    "    preview(pd.DataFrame({'note': ['plots skipped or no data']}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
